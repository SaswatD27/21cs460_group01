{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS460 FL 1.01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaswatD27/21cs460_group01/blob/main/Code/CS460_FL_1_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0HdWCBSThU5"
      },
      "source": [
        "## Notes\n",
        "* Current client side implementation just helps create initial model; no server2client communication yet, no preexisting initial model. Is this necessary? Don't think so, not for now.\n",
        "* Will Noising before Aggregation FL work? Let us see. Perhaps the exponential mechanism will be better. (Implemented, works, hmm... what's the error margin now?)\n",
        "* Need to add error/loss function graph\n",
        "* Need to decouple n_k from training functions to apply some algorithms and make it more natural - Update: Done\n",
        "* IMPORTANT:  Need testing set (might not but still, for propriety; client-side) - Update: Done\n",
        "* Gaussian noise addition (Client side) works but might be identifying, implement mixes/LDP/random subsampling of returned weights?\n",
        "* IMPORTANT: Look at the implementation of Vanilla FedAvg and pass values according to that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdsCx-WWD5Hr"
      },
      "source": [
        "def error_plot(k, train_err, test_err, title1, title2, x_title):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(k, train_err, color='Black')\n",
        "    plt.xlabel(x_title)\n",
        "    plt.ylabel('Average Training Error')\n",
        "    plt.title(title1, y=1.08)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(k, test_err, color='Blue')\n",
        "    plt.xlabel(x_title)\n",
        "    plt.ylabel('Average Testing Error')\n",
        "    plt.title(title2, y=1.08)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E58-dIg2yGo"
      },
      "source": [
        "## Client Side"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_cGo_SSDYEJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a33bdc15-c3b5-4674-fb71-f39b5be01d41"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "w_n=7 #cardinality of weight vector\n",
        "\n",
        "def get_data(m, n): #Generates data with linear trend\n",
        "    x_cord = []\n",
        "    y_cord = []\n",
        "    for i in range(n):\n",
        "        x = np.random.rand(w_n)\n",
        "        y = np.dot(m,x)\n",
        "        x_cord.append(x)\n",
        "        y_cord.append(y)\n",
        "    return x_cord, y_cord\n",
        "\n",
        "k=500\n",
        "#m=np.random.rand(w_n) #slope parameter\n",
        "#m[0]=1\n",
        "m=[1,2,4,3,5,6,1.2]\n",
        "print(m)\n",
        "n_k_dev= np.random.randint(100,1000,k)\n",
        "x, y = get_data(m, sum(n_k_dev))\n",
        "i=0\n",
        "x_cord = []\n",
        "y_cord = []\n",
        "\n",
        "testing_x, testing_y = get_data(m, 100)\n",
        "\n",
        "for n0 in n_k_dev:\n",
        "    x_cord.append(x[i:i+n0])\n",
        "    y_cord.append(y[i:i+n0])\n",
        "    i+=n0\n",
        "\n",
        "#print(x_cord, y_cord)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwjNE0-DeSl"
      },
      "source": [
        "def SGD_(m, n, iteration, x_cord, y_cord, alpha): #Performs client side SGD\n",
        "    for p in range(iteration):\n",
        "        for i in range(n):\n",
        "            #print((p/iteration)*100,(i*100)/n)\n",
        "            j = random.randint(0, n - 1)\n",
        "            x_i = x_cord[j]\n",
        "            y_a = y_cord[j]\n",
        "            y_p = np.dot(m,x_i)\n",
        "            # error = (y_p - y_a) ** 2\n",
        "            dm = 2 * x_i * (y_p - y_a)\n",
        "            m = m - alpha * dm\n",
        "    return m\n",
        "\n",
        "\"\"\"\n",
        "def dat_plot(x_cord, y_cord, m1, c1, m2, c2, n, title1, title2): #Plots scatter/line graphs; displaying results of learning\n",
        "    x_ = []\n",
        "    y_1 = []\n",
        "    y_2 = []\n",
        "    for i in range(n):\n",
        "        x = x_cord[i]\n",
        "        y1 = m1 * x + c1\n",
        "        y2 = m2 * x + c2\n",
        "        x_.append(x)\n",
        "        y_1.append(y1)\n",
        "        y_2.append(y2)\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(x_cord, y_cord)\n",
        "    plt.plot(x_, y_1, color='Black')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.title(title1)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.scatter(x_cord, y_cord)\n",
        "    plt.plot(x_, y_2, color='Blue')\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "    plt.title(title2)\n",
        "    plt.show()\n",
        "\"\"\"\n",
        "\n",
        "def no_of_pts(id):\n",
        "  return n_k_dev[id]\n",
        "\n",
        "def fetch_coords(id):\n",
        "  return x_cord[id], y_cord[id]\n",
        "\n",
        "def device_local_learning(alp_, w, id, itern): #Conducts local training for SGD and outputs weight vector\n",
        "    #m = 5\n",
        "    #n_k = random.randint(1, 100)\n",
        "    #x_cord, y_cord = get_data(m, n_k)\n",
        "    n_k = no_of_pts(id)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w = SGD_(w, n_k, itern, x_cord, y_cord, alp_)\n",
        "    #print(id,w)\n",
        "    # plot(x_cord,y_cord,w_,b_,n_k)\n",
        "    return w, n_k"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDHd2XNC4ZQc"
      },
      "source": [
        "def flatten(t):\n",
        "    return [item for sublist in t for item in sublist]\n",
        "\n",
        "x_cordflat=flatten(x_cord)\n",
        "y_cordflat=flatten(y_cord)\n",
        "\n",
        "def average_training_error(w):\n",
        "  error=0\n",
        "  for i in range(sum(n_k_dev)):\n",
        "    y_p=np.dot(w,x_cordflat[i])\n",
        "    y_a=y_cordflat[i]\n",
        "    #print(i)\n",
        "    error+=(y_a-y_p)**2\n",
        "  error*=(1/sum(n_k_dev))\n",
        "  return error\n",
        "\n",
        "def average_testing_error(w):\n",
        "  error=0\n",
        "  for i in range(len(testing_x)):\n",
        "    y_p=np.dot(w,testing_x[i])\n",
        "    y_a=testing_y[i]\n",
        "    #print(i)\n",
        "    error+=(y_a-y_p)**2\n",
        "  error*=(1/len(testing_x))\n",
        "  return error"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGM51V4lhMhZ",
        "outputId": "678762fc-d6eb-4f9c-8521-bca31f7de5b8"
      },
      "source": [
        "print(len(x_cordflat))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zLsgnwlGGAe"
      },
      "source": [
        "## 0. Centralised Learning (as a baseline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "hcZaMo-5GMFa",
        "outputId": "88ce5760-e5a0-457f-a861-800cd919b135"
      },
      "source": [
        "def centralised_learning(x_cord,y_cord, w_n, itern, alpha):\n",
        "  x_flat=flatten(x_cord)\n",
        "  y_flat=flatten(y_cord)\n",
        "  w=np.random.rand(w_n)\n",
        "  w_fin=SGD_(w,len(x_flat), itern, x_flat, y_flat, alpha)\n",
        "  return w_fin\n",
        "\n",
        "itern=100\n",
        "alpha=0.01\n",
        "time1=time.time()\n",
        "w0=centralised_learning(x_cord,y_cord,w_n,itern,alpha)\n",
        "time2=time.time()\n",
        "print(w0,\"\\n Time taken = \",time2-time1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-628cae036715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtime1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mw0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcentralised_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_cord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitern\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtime2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n Time taken = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-628cae036715>\u001b[0m in \u001b[0;36mcentralised_learning\u001b[0;34m(x_cord, y_cord, w_n, itern, alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0my_flat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mw_fin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mw_fin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-e2afb7734720>\u001b[0m in \u001b[0;36mSGD_\u001b[0;34m(m, n, iteration, x_cord, y_cord, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# error = (y_p - y_a) ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8fVC9fUOf5J",
        "outputId": "03f7fada-04e6-4860-e8d1-63dbf8cf4444"
      },
      "source": [
        "#w0=[1, 0.00178753, 0.50501066, 0.67235608, 0.98434998, 0.45182414, 0.85024702] \n",
        "print(\"Average Training Error for Centralised Learning on SGD = \",average_training_error(w0),\"\\nAverage Testing Error for Centralised Learning on SGD = \", average_testing_error(w0))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for Centralised Learning on SGD =  4.209352931600863e-29 \n",
            "Average Testing Error for Centralised Learning on SGD =  4.0894549326657255e-29\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Wxa0OlT0b8"
      },
      "source": [
        "## Server Side\n",
        "### 1. FedAvg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWiOee8WRI2g"
      },
      "source": [
        "def federated_avg(w_, n_k):\n",
        "    n_ = np.sum(n_k)\n",
        "    w_k = 0\n",
        "    for p in range(len(n_k)):\n",
        "        w_k += (n_k[p] * w_[p]) / n_\n",
        "    return w_k\n",
        "\n",
        "\n",
        "def SGD_federated_learning(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    w_ = np.zeros((int(C * K * T), w_n))\n",
        "    n_k = np.zeros(int(C * K * T))\n",
        "    z=0\n",
        "    for i in range(T):\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_local_learning(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        print(i,\" done.\")\n",
        "    w_k = federated_avg(w_, n_k)\n",
        "    return w_k\n",
        "\n",
        "def SGD_federated_learning_plt(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    w_k=[]\n",
        "    for i in range(T):\n",
        "        w_ = []\n",
        "        n_k = []\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        z=0\n",
        "        for j in training_subset:\n",
        "            dev_res = device_local_learning(alp_, w, j, n)\n",
        "            w_.append(dev_res[0])\n",
        "            n_k.append(dev_res[1])\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        w_k.append(federated_avg(training_subset, w_, n_k))\n",
        "        print(i,\" done.\")\n",
        "    return w_k"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBFg7nx22rf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc6383a-1efa-4793-89d1-21dd950b54bb"
      },
      "source": [
        "T = 5  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = np.random.rand(7)\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w1 = SGD_federated_learning(T, K, C, w, n, alp_)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w1)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w1, b1, n_k, title1=\"FedAvg on SGD\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  done.\n",
            "1  done.\n",
            "2  done.\n",
            "Time taken for SGD federated learning 201.61977124214172 \n",
            " w = [1.00000002 2.         3.99999999 3.00000001 4.99999999 5.99999999\n",
            " 1.2       ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsA1Eb5y5VeT",
        "outputId": "4310276b-c544-4d56-c19b-9fd3eb890c77"
      },
      "source": [
        "print(\"Average Training Error for Vanilla FedAvg on SGD = \",average_training_error(w1),\"\\nAverage Testing Error for Vanilla FedAvg on SGD = \", average_testing_error(w1))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for Vanilla FedAvg on SGD =  6.032714489677551e-17 \n",
            "Average Testing Error for Vanilla FedAvg on SGD =  6.132554212538585e-17\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "S_IIH3vrFx6u",
        "outputId": "4ce7c843-311e-405f-cca2-9bc8855cdc96"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "T=100\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = np.random.rand(7)\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "FedAvg_training_errors=[]\n",
        "FedAvg_testing_errors=[]\n",
        "w1 = SGD_federated_learning_plt(T, K, C, w, n, alp_)\n",
        "for w_iter in w1:\n",
        "  FedAvg_training_errors.append(average_training_error(w_iter))\n",
        "  FedAvg_testing_errors.append(average_testing_error(w_iter))\n",
        "#print(T1,\" done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  done.\n",
            "1  done.\n",
            "2  done.\n",
            "3  done.\n",
            "4  done.\n",
            "5  done.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-30f3a90f970e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mFedAvg_training_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mFedAvg_testing_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_federated_learning_plt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mFedAvg_training_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_training_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-0b05d796bfb1>\u001b[0m in \u001b[0;36mSGD_federated_learning_plt\u001b[0;34m(T, K, C, w, n, alp_)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mdev_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_local_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mw_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mn_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e2afb7734720>\u001b[0m in \u001b[0;36mdevice_local_learning\u001b[0;34m(alp_, w, id, itern)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mn_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_of_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m#print(id,w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# plot(x_cord,y_cord,w_,b_,n_k)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e2afb7734720>\u001b[0m in \u001b[0;36mSGD_\u001b[0;34m(m, n, iteration, x_cord, y_cord, alpha)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0my_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;31m# error = (y_p - y_a) ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IvSwYw9IEj9"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "print(w1)\n",
        "print(FedAvg_training_errors)\n",
        "error_plot(np.arange(1,10+1,1), FedAvg_training_errors, FedAvg_testing_errors, \"Training Error for Vanilla FedAvg\", \"Testing Error for Vanilla FedAvg\", \"Number of Rounds (T)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOjm9_6xMsC2"
      },
      "source": [
        "##2. FedAvg with Gaussian Noise Added ($(\\varepsilon,\\delta)-$DP)\n",
        "A.K.A Noising before Aggregation FL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKb-S3VKTRGA"
      },
      "source": [
        "def device_nbafederated_learning(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    delta=0.01\n",
        "    eps=70\n",
        "    C=1.01*max([abs(i) for i in m])\n",
        "    w=np.zeros(len(w_))\n",
        "    for i in range(len(w)):\n",
        "      w[i]=w_[i]*(1/(max([1,max(w_)/C])))\n",
        "    #return w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w)), n_k\n",
        "    return w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2)), n_k"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HylQxRyy_ku"
      },
      "source": [
        "def SGD_nbafederated_learning(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    w_ = np.zeros((int(C * K * T), w_n))\n",
        "    n_k = np.zeros(int(C * K * T))\n",
        "    z=0\n",
        "    for i in range(T):\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_nbafederated_learning(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "    w_k = federated_avg(w_[:z], n_k[:z])\n",
        "    return w_k\n",
        "\n",
        "def SGD_nbafederated_learning_plt(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    w_k=[]\n",
        "    for i in range(T):\n",
        "        w_ = []\n",
        "        n_k = []\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        z=0\n",
        "        for j in training_subset:\n",
        "            dev_res = device_nbafederated_learning(alp_, w, j, n)\n",
        "            w_.append(dev_res[0])\n",
        "            n_k.append(dev_res[1])\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        w_k.append(federated_avg(training_subset, w_, n_k))\n",
        "        print(i,\" done.\")\n",
        "    return w_k"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct6QYs_PzRFL",
        "outputId": "6b4a8a96-b7a5-4bf7-ac8a-0335a42399de"
      },
      "source": [
        "T = 5  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100 # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w2 = SGD_nbafederated_learning(T, K, C, w, n, alp_)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w2)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for SGD federated learning 333.9982795715332 \n",
            " w = [0.99995165 1.99995165 3.99995165 2.99995165 4.99995164 5.99995164\n",
            " 1.19995165]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH7iSwIG9CEU",
        "outputId": "752dafa3-b308-4f45-897a-481c5dc13b88"
      },
      "source": [
        "print(\"Average Training Error for NbA FedAvg on SGD = \",average_training_error(w2),\"\\nAverage Testing Error for NbA FedAvg on SGD = \", average_testing_error(w2))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for NbA FedAvg on SGD =  2.998740672656647e-08 \n",
            "Average Testing Error for NbA FedAvg on SGD =  2.9509814243729675e-08\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "1-1pEFpQbmxa",
        "outputId": "dcf3a8d3-dcc5-4f4c-8db7-d6f5a89667cf"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "T=10\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = np.random.rand(7)\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "NbAFL_training_errors=[]\n",
        "NbAFL_testing_errors=[]\n",
        "w2 = SGD_nbafederated_learning_plt(T, K, C, w, n, alp_)\n",
        "for w in w2:\n",
        "  NbAFL_training_errors.append(average_training_error(w))\n",
        "  NbAFL_testing_errors.append(average_testing_error(w))\n",
        "#print(T1,\" done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-fab0d2450e3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mNbAFL_training_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mNbAFL_testing_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_nbafederated_learning_plt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mNbAFL_training_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_training_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-121-3dafbbca0670>\u001b[0m in \u001b[0;36mSGD_nbafederated_learning_plt\u001b[0;34m(T, K, C, w, n, alp_)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mdev_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_nbafederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mw_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mn_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-128-a92409df8e92>\u001b[0m in \u001b[0;36mdevice_nbafederated_learning\u001b[0;34m(alp_, w, id, n)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mn_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_of_pts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mw_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-e2afb7734720>\u001b[0m in \u001b[0;36mSGD_\u001b[0;34m(m, n, iteration, x_cord, y_cord, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# error = (y_p - y_a) ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "iuNmiRXucB0r",
        "outputId": "ea4891b9-242f-4263-8424-9dbe71703a85"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "print(NbAFL_training_errors)\n",
        "error_plot(np.arange(1,10+1,1), NbAFL_training_errors, NbAFL_testing_errors, \"Training Error for NbA FedAvg\", \"Testing Error for NbA FedAvg\", \"Number of Rounds (T)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.01158681812342535, 0.0039639693555363715, 0.006762733400813069, 0.003372911850865451, 0.0024082963555250698, 0.0021561038018250754, 0.007480583362887749, 0.000844540983616561, 0.011941079390941519, 0.0014843900783643536]\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvF1bTZ4cTLv"
      },
      "source": [
        "## 3. Reduce Communication Overhead (Volume)\n",
        "Probabilistic Quantisation\n",
        "\n",
        "Weight Subsampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HhSqX1jfsae"
      },
      "source": [
        "def prob_quant(w):\n",
        "  w_min=min(w)\n",
        "  w_max=max(w)\n",
        "  wq=np.zeros(len(w))\n",
        "  for i in range(len(w)):\n",
        "    wq[i]=np.random.choice([w_min,w_max],[(w_max-w[i])/(w_max-w_min),1-((w_max-w[i])/(w_max-w_min))])\n",
        "  return wq\n",
        "def device_redcommfederated_learning(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    delta=0.01\n",
        "    eps=2\n",
        "    C=5.1\n",
        "    w=np.zeros(len(w_))\n",
        "    for i in range(len(w)):\n",
        "      w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w)), n_k\n",
        "    return prob_quant(w)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NFq15M6cZvu"
      },
      "source": [
        "## 4. Another Attempt : Adding Random Masking\n",
        "With Static Subsampling as earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3uOeSQvONc5"
      },
      "source": [
        "def device_nbafederated_learning2(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    delta=0.01\n",
        "    eps=2\n",
        "    C=5.1\n",
        "    w=np.zeros(len(w_))\n",
        "    for i in range(len(w)):\n",
        "      w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    #print(\"w_g = \",w_g)\n",
        "    s=0.25\n",
        "    #np.random.seed(seed)\n",
        "    ind=np.random.choice(np.arange(len(w)),size=int((1-s)*len(w)))\n",
        "    mask = np.zeros(len(w))\n",
        "    for i in range(len(w)):\n",
        "      if i in ind:\n",
        "        mask[i]=1\n",
        "    #print(w_g*mask)\n",
        "    return w_g*mask,n_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQq8dG9AgRQq"
      },
      "source": [
        "def federated_avg2(training_subset, w_, n_k):\n",
        "    #n_ = np.sum(n_k)*(0.75)\n",
        "    w_k = []\n",
        "    #n_ind=np.zeros(w_n)\n",
        "    for p in range(len(n_k)):\n",
        "        w_k.append(n_k[p] * w_[p])\n",
        "    w_1=np.transpose(w_k)\n",
        "    #update n_ind with n_k\n",
        "    for i in w_1:\n",
        "      for j in range(len(i)):\n",
        "        if i[j]!=0:\n",
        "          i[j]=1\n",
        "      i*=n_k\n",
        "    #n_ind=[np.count_nonzero(i) for i in w_1]\n",
        "    n_ind=[sum(i) for i in w_1]\n",
        "    #print(\"n_ind=\",n_ind)\n",
        "    w=0\n",
        "    for p in range(len(training_subset)):\n",
        "        w+=(n_k[p]*w_[p])/n_ind\n",
        "    return w\n",
        "def SGD_nbafederated_learning2(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    seeds=[]\n",
        "    w_ = np.zeros((int(C * K * T), w_n))\n",
        "    n_k = np.zeros(int(C * K * T))\n",
        "    z=0\n",
        "    for i in range(T):\n",
        "        #np.random.seed()\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_nbafederated_learning2(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "    w_k = federated_avg2(training_subset, w_, n_k)\n",
        "    return w_k\n",
        "\n",
        "def SGD_nbafederated_learning2_plt(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    w_k=[]\n",
        "    for i in range(T):\n",
        "        #np.random.seed()\n",
        "        w_ = []\n",
        "        n_k = []\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        z=0\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            dev_res = device_nbafederated_learning2(alp_, w, j, n)\n",
        "            w_.append(dev_res[0])\n",
        "            n_k.append(dev_res[1])\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        w_k.append(federated_avg2(w_, n_k))\n",
        "        print(i,\" done.\")\n",
        "    return w_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lXy-e90gZG_",
        "outputId": "956c46a8-69c9-40c1-8945-0c9b324913bf"
      },
      "source": [
        "T = 5  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w2 = SGD_nbafederated_learning2(T, K, C, w, n, alp_)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w2)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for SGD federated learning 365.5682189464569 \n",
            " w = [1.34437206 2.34183301 3.56094899 4.03797441 5.39339701 5.25008139\n",
            " 1.25352552]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNLf0i5Yggmh",
        "outputId": "8a28abba-9049-44fc-8297-488c641ba98f"
      },
      "source": [
        "print(\"Average Training Error for NbA FedAvg w/ Random Mask on SGD = \",average_training_error(w2),\"\\nAverage Testing Error for NbA FedAvg w/ Random Mask on SGD = \", average_testing_error(w2))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for NbA FedAvg w/ Random Mask on SGD =  0.13101611851098324 \n",
            "Average Testing Error for NbA FedAvg w/ Random Mask on SGD =  0.13036598162280666\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W572aVc6uY6U",
        "outputId": "ff3e6459-e370-4965-94ac-ba7dc726ce0b"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "T=100\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = np.random.rand(7)\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "RM_training_errors=[]\n",
        "RM_testing_errors=[]\n",
        "w2 = SGD_nbafederated_learning2_plt(T, K, C, w, n, alp_)\n",
        "for w_iter in w2:\n",
        "  RM_training_errors.append(average_training_error(w_iter))\n",
        "  RM_testing_errors.append(average_testing_error(w_iter))\n",
        "#print(T1,\" done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0  done.\n",
            "1  done.\n",
            "2  done.\n",
            "3  done.\n",
            "4  done.\n",
            "5  done.\n",
            "6  done.\n",
            "7  done.\n",
            "8  done.\n",
            "9  done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6vct950rZP"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "print(RM_training_errors)\n",
        "error_plot(np.arange(1,10+1,1), RM_training_errors, RM_testing_errors, \"Training Error;\", \"Testing Error for Random Masked, NbA FedAvg\", \"Number of Rounds (T)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbX-yN-qh5xF"
      },
      "source": [
        "## 6. NbAFL with Probabilistic Quantisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQZiF0VNiErb"
      },
      "source": [
        "def prob_quant(w):\n",
        "  w_min=min(w)\n",
        "  w_max=max(w)\n",
        "  wq=np.zeros(len(w))\n",
        "  for i in range(len(w)):\n",
        "    wq[i]=float(np.random.choice([w_min,w_max],p=[((w_max-w[i])/(w_max-w_min)),(1-((w_max-w[i])/(w_max-w_min)))]))\n",
        "  return wq\n",
        "def device_nbafederated_learning_pq(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    delta=0.01\n",
        "    eps=70\n",
        "    C=1.01*max(m)\n",
        "    w=np.zeros(len(w_))\n",
        "    for i in range(len(w)):\n",
        "      w[i]=w_[i]*(1/(max([1,max(w_)/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    return prob_quant(w_g), n_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5usmdogscYX"
      },
      "source": [
        "def SGD_nbafederated_learning_pq(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    for i in range(T):\n",
        "        w_ = np.zeros((int(C * K * T), w_n))\n",
        "        n_k = np.zeros(int(C * K * T))\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        z=0\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_nbafederated_learning_pq(alp_, w, j, n)\n",
        "            #print(i,z)\n",
        "            z+=1\n",
        "    w_k = federated_avg(training_subset, w_, n_k)\n",
        "    return w_k\n",
        "def SGD_nbafederated_learning_pq_plt(T, K, C, w, n, alp_):\n",
        "    k = np.arange(K)\n",
        "    w_ = []\n",
        "    n_k = []\n",
        "    z=0\n",
        "    # Train for T many rounds\n",
        "    for i in range(T):\n",
        "        training_subset = np.random.randint(0, K, int(C * K))\n",
        "        for j in training_subset:\n",
        "            dev_res = device_nbafederated_learning_pq(alp_, w, j, n)\n",
        "            w.append(dev_res[0])\n",
        "            n_k.append(dev_res[1])\n",
        "            #print(i,z)\n",
        "            z+=1\n",
        "        w_k.append(federated_avg(training_subset, w_[:z], n_k[:z]))\n",
        "        print(i,\" done.\")\n",
        "    return w_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oac1J4HYsnnZ",
        "outputId": "ae7c62ea-6d4a-4303-c451-19a06b3fc731"
      },
      "source": [
        "T = 15  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w_pq = SGD_nbafederated_learning_pq(T, K, C, w, n, alp_)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning with probabilistic binarisation\", time2 - time1,\"\\n w =\",w_pq)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for SGD federated learning with probabilistic binarisation 1095.7553567886353 \n",
            " w = [1.00024326 2.14072738 3.97115855 3.20425608 5.23787382 6.00072659\n",
            " 1.21816426]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YNX1wZZwaGl",
        "outputId": "e3c60b72-0a87-4b24-b318-006fb89cf952"
      },
      "source": [
        "print(\"Average Training Error for NbA FedAvg w/ Probabilistic Binarisation on SGD = \",average_training_error(w_pq),\"\\nAverage Testing Error for NbA FedAvg w/ Probabilistic Binarisation on SGD = \", average_testing_error(w_pq))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for NbA FedAvg w/ Probabilistic Binarisation on SGD =  0.09210373561474153 \n",
            "Average Testing Error for NbA FedAvg w/ Probabilistic Binarisation on SGD =  0.09383845621004694\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0_9iuKLs5bQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "0u3sJKqG1ih5",
        "outputId": "1de28316-3b4b-49dc-d271-a9e63ec6af4e"
      },
      "source": [
        "#RUN FOR ERROR PLOT\n",
        "T=100\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = np.random.rand(7)\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "RM_training_errors=[]\n",
        "RM_testing_errors=[]\n",
        "w2 = SGD_nbafederated_learning2_plt(T, K, C, w, n, alp_)\n",
        "for w_iter in w2:\n",
        "  RM_training_errors.append(average_training_error(w_iter))\n",
        "  RM_testing_errors.append(average_testing_error(w_iter))\n",
        "#print(T1,\" done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-a5fb71b1bdd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mRM_training_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mRM_testing_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_nbafederated_learning2_plt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw_iter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mRM_training_errors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_training_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-341d9d8ac492>\u001b[0m in \u001b[0;36mSGD_nbafederated_learning2_plt\u001b[0;34m(T, K, C, w, n, alp_)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m#np.random.rand(seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mdev_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_nbafederated_learning2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mw_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mn_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-83621d41a275>\u001b[0m in \u001b[0;36mdevice_nbafederated_learning2\u001b[0;34m(alp_, w, id, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m#n_k.append(n_k0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mw_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-e2afb7734720>\u001b[0m in \u001b[0;36mSGD_\u001b[0;34m(m, n, iteration, x_cord, y_cord, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# error = (y_p - y_a) ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy4BLeYI0lxC"
      },
      "source": [
        "## 5. Random Masking, with Dynamic Subsampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfeG0VE304-s"
      },
      "source": [
        "def device_nbafederated_learning3(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    delta=0.01\n",
        "    eps=2\n",
        "    C=5.1\n",
        "    w=np.zeros(len(w_))\n",
        "    for i in range(len(w)):\n",
        "      w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    #print(\"w_g = \",w_g)\n",
        "    s=0.25\n",
        "    #np.random.seed(seed)\n",
        "    ind=np.random.choice(np.arange(len(w)),size=int((1-s)*len(w)))\n",
        "    mask = np.zeros(len(w))\n",
        "    for i in range(len(w)):\n",
        "      if i in ind:\n",
        "        mask[i]=1\n",
        "    #print(w_g*mask)\n",
        "    return w_g*mask,n_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGaI98lt08aB"
      },
      "source": [
        "def federated_avg3(training_subset, w_, n_k):\n",
        "    #n_ = np.sum(n_k)*(0.75)\n",
        "    w_k = []\n",
        "    #n_ind=np.zeros(w_n)\n",
        "    for p in range(len(n_k)):\n",
        "        w_k.append(n_k[p] * w_[p])\n",
        "    w_1=np.transpose(w_k)\n",
        "    #update n_ind with n_k\n",
        "    for i in w_1:\n",
        "      for j in range(len(i)):\n",
        "        if i[j]!=0:\n",
        "          i[j]=1\n",
        "      i*=n_k\n",
        "    #n_ind=[np.count_nonzero(i) for i in w_1]\n",
        "    n_ind=[sum(i) for i in w_1]\n",
        "    print(\"n_ind=\",n_ind) \n",
        "    w=0\n",
        "    for p in range(len(n_k)):\n",
        "        w+=(n_k[p]*w_[p])/n_ind\n",
        "    return w\n",
        "def SGD_nbafederated_learning3(T, K, C, w, n, alp_, beta):\n",
        "    k = np.arange(K)\n",
        "    w_ = np.zeros((int(c * K * T), w_n))\n",
        "    n_k = np.zeros(int(c * K * T))\n",
        "    z=0\n",
        "    # Train for T many rounds\n",
        "    seeds=[]\n",
        "    for i in range(T):\n",
        "        c=C*(1/math.exp(beta*i))\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(c * K))\n",
        "\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_nbafederated_learning3(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "    w_k = federated_avg3(training_subset, w_[:z], n_k[:z])\n",
        "    return w_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J49Cr56t0_eJ",
        "outputId": "d1bbc336-70ac-4d07-d2a8-a69989bd8726"
      },
      "source": [
        "T = 5  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "beta= 0.05\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w_dyn = SGD_nbafederated_learning3(T, K, C, w, n, alp_, beta)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w_dyn)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_ind= [25810.0, 25540.0, 30010.0, 31974.0, 36586.0, 31664.0, 31155.0]\n",
            "Time taken for SGD federated learning 333.9241933822632 \n",
            " w = [1.13882268 2.08542777 3.96749625 2.73184596 4.96160552 5.05543362\n",
            " 0.61048951]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dHHHrpR1Vub",
        "outputId": "4acfa590-0d54-4093-a686-ef7fb281cbb3"
      },
      "source": [
        "print(\"Average Training Error for NbA FedAvg w/ Random Mask on SGD = \",average_training_error(w_dyn),\"\\nAverage Testing Error for NbA FedAvg w/ Random Mask on SGD = \", average_testing_error(w_dyn))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for NbA FedAvg w/ Random Mask on SGD =  0.7900591789217705 \n",
            "Average Testing Error for NbA FedAvg w/ Random Mask on SGD =  0.9164836574369606\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA_fmddqIGEr"
      },
      "source": [
        "def error_plot(k, sgd_err, mini_err, title1, title2, x_title):\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(k, sgd_err, color='Black')\n",
        "    plt.xlabel(x_title)\n",
        "    plt.ylabel('Average Error')\n",
        "    plt.title(title1)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(k, mini_err, color='Blue')\n",
        "    plt.xlabel(x_title)\n",
        "    plt.ylabel('Average Error')\n",
        "    plt.title(title2)\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "PEi8g4NLIN2U",
        "outputId": "05d0ed36-72eb-4189-b2d0-1f3340f041ab"
      },
      "source": [
        "m = 5  # slope parameter\n",
        "T = 1  # No of federated learning rounds\n",
        "C = 0.25 # fraction of nodes used at each iteration\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pulling\n",
        "alp_ = 0.01\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "k_=[]\n",
        "sgd_error=[]\n",
        "mini_error=[]\n",
        "for k_n in range(50,500,50):\n",
        "    n_k_dev = np.random.randint(100, 1000, k_n)\n",
        "    x, y = get_data(m, sum(n_k_dev))\n",
        "    i = 0\n",
        "    x_cord = []\n",
        "    y_cord = []\n",
        "    for n0 in n_k_dev:\n",
        "        x_cord.append(x[i:i + n0])\n",
        "        y_cord.append(y[i:i + n0])\n",
        "        i += n0\n",
        "    x_cordflat = flatten(x_cord)\n",
        "    y_cordflat = flatten(y_cord)\n",
        "    k_.append(k_n)\n",
        "    w1, b1 = SGD_federated_learning(T, k_n, C, w, b, n, alp_)\n",
        "    sgd_error.append(average_error(w1, b1))\n",
        "    w2, b2 = Mini_federated_learning(T, k_n, C, w, b, n, alp_)\n",
        "    mini_error.append(average_error(w2,b2))\n",
        "error_plot(k_,sgd_error,mini_error,title1=\"FedAvg on SGD\",title2=\"FedAvg on mini-SGD\",x_title=\"Total number of clients\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-588b1d7e0bfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0my_cordflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_cord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mk_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_federated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0msgd_error\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMini_federated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SGD_federated_learning() takes 6 positional arguments but 7 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLHUoVwPIelR"
      },
      "source": [
        "c_=[]\n",
        "sgd_error=[]\n",
        "mini_error=[]\n",
        "for c_n in range(20,120,20):\n",
        "    c_n=c_n/100\n",
        "    n_k_dev = np.random.randint(100, 1000, K)\n",
        "    x, y = get_data(m, sum(n_k_dev))\n",
        "    i = 0\n",
        "    x_cord = []\n",
        "    y_cord = []\n",
        "    for n0 in n_k_dev:\n",
        "        x_cord.append(x[i:i + n0])\n",
        "        y_cord.append(y[i:i + n0])\n",
        "        i += n0\n",
        "    x_cordflat = flatten(x_cord)\n",
        "    y_cordflat = flatten(y_cord)\n",
        "    c_.append(c_n)\n",
        "    w1, b1 = SGD_federated_learning(T, K, c_n, w, b, n, alp_)\n",
        "    sgd_error.append(average_error(w1, b1))\n",
        "    w2, b2 = Mini_federated_learning(T, K, c_n, w, b, n, alp_)\n",
        "    mini_error.append(average_error(w2,b2))\n",
        "error_plot(c_,sgd_error,mini_error,title1=\"FedAvg on SGD\",title2=\"FedAvg on mini-SGD\",x_title=\"Fraction of clients used for learning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSkoihn85fqU"
      },
      "source": [
        "## 6. Dynamic Subsampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2DNRv9B5pI8"
      },
      "source": [
        "def device_federated_learning_dyn_samp(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    #delta=0.01\n",
        "    #eps=2\n",
        "    #C=5.1\n",
        "    #w=np.zeros(len(w_))\n",
        "    #for i in range(len(w)):\n",
        "    #  w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    #print(\"w_g = \",w_g)\n",
        "    #s=0.25\n",
        "    #np.random.seed(seed)\n",
        "    #ind=np.random.choice(np.arange(len(w)),size=int((1-s)*len(w)))\n",
        "    #mask = np.zeros(len(w))\n",
        "    #for i in range(len(w)):\n",
        "    #  if i in ind:\n",
        "    #    mask[i]=1\n",
        "    #print(w_g*mask)\n",
        "    return w_,n_k"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK-i83nB6Cum"
      },
      "source": [
        "def SGD_federated_learning_dyn_samp(T, K, C, w, n, alp_, beta):\n",
        "    k = np.arange(K)\n",
        "    # Train for T many rounds\n",
        "    seeds=[]\n",
        "    w_ = np.zeros((int(C * K * T), w_n))\n",
        "    n_k = np.zeros(int(C * K * T))\n",
        "    z=0\n",
        "    for i in range(T):\n",
        "        c=C*(1/math.exp(beta*i))\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(c * K))\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_federated_learning_dyn_samp(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "    w_k = federated_avg(w_[:z], n_k[:z])\n",
        "    return w_k"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RDwUqIJ6bnL"
      },
      "source": [
        "T = 3  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "beta= 0.05\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w_dyn = SGD_federated_learning_dyn_samp(T, K, C, w, n, alp_, beta)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w_dyn)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qt4fbtj172ca",
        "outputId": "c5c0410e-3247-409e-a4cb-ee777d4559e1"
      },
      "source": [
        "print(\"Average Training Error for FedAvg w/ Dyn Sampling on SGD = \",average_training_error(w_dyn),\"\\nAverage Testing Error for FedAvg w/ Dyn Sampling on SGD = \", average_testing_error(w_dyn))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for FedAvg w/ Dyn Sampling on SGD =  4.708314660096173e-18 \n",
            "Average Testing Error for FedAvg w/ Dyn Sampling on SGD =  5.280313205126087e-18\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ouN1amv8PGX"
      },
      "source": [
        "## 1.* Adaptive Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J7Jdw7S8U89"
      },
      "source": [
        "def device_federated_learning_adap_samp(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    #delta=0.01\n",
        "    #eps=2\n",
        "    #C=5.1\n",
        "    #w=np.zeros(len(w_))\n",
        "    #for i in range(len(w)):\n",
        "    #  w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    #print(\"w_g = \",w_g)\n",
        "    #s=0.25\n",
        "    #np.random.seed(seed)\n",
        "    #ind=np.random.choice(np.arange(len(w)),size=int((1-s)*len(w)))\n",
        "    #mask = np.zeros(len(w))\n",
        "    #for i in range(len(w)):\n",
        "    #  if i in ind:\n",
        "    #    mask[i]=1\n",
        "    #print(w_g*mask)\n",
        "    return w_,n_k"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5_ruC8A8cCe"
      },
      "source": [
        "def SGD_federated_learning_adap_samp(T, K, C, w, n, alp_, beta):\n",
        "    k = np.arange(K)\n",
        "    beta0=beta\n",
        "    error=[]\n",
        "    error_t=0\n",
        "    w_ = np.zeros((int(C * K * T), w_n))\n",
        "    n_k = np.zeros(int(C * K * T))\n",
        "    z=0\n",
        "    # Train for T many rounds\n",
        "    for i in range(T):\n",
        "        c=C*(1/math.exp(beta0*i))\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(c * K))\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_federated_learning_adap_samp(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        w_k = federated_avg(w_[:z], n_k[:z])\n",
        "        error.append(average_testing_error(w_k))\n",
        "        if i>0:\n",
        "          if error[i]>error[i-1]:\n",
        "            beta0*=((error[i]/error[i-1])*(i/i+1))\n",
        "            error_t=error[i-1]\n",
        "        #if beta0!=beta:\n",
        "        #  if error[i]<=error_t:\n",
        "        #    beta0=beta\n",
        "    #w_k = federated_avg(training_subset, w_, n_k)\n",
        "    return w_k"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "0FXdhAl1-La3",
        "outputId": "82826a68-6dd8-4106-f238-6ae7df003001"
      },
      "source": [
        "T = 3  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "beta= 0.05\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w_dyn = SGD_federated_learning_adap_samp(T, K, C, w, n, alp_, beta)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w_dyn)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-122686e93c36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtime1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mw_dyn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_federated_learning_adap_samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtime2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken for SGD federated learning\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n w =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_dyn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-eb8514bfee0e>\u001b[0m in \u001b[0;36mSGD_federated_learning_adap_samp\u001b[0;34m(T, K, C, w, n, alp_, beta)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#np.random.rand(seed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_subset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mw_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdevice_federated_learning_adap_samp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malp_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m#print(z)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-58d53905b3ba>\u001b[0m in \u001b[0;36mdevice_federated_learning_adap_samp\u001b[0;34m(alp_, w, id, n)\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0;31m#n_k.append(n_k0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfetch_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mw_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSGD_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malp_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m#delta=0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#eps=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-e2afb7734720>\u001b[0m in \u001b[0;36mSGD_\u001b[0;34m(m, n, iteration, x_cord, y_cord, alpha)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;31m# error = (y_p - y_a) ** 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG_L33Vj_1h1",
        "outputId": "067d09c6-bcff-4a70-8673-9f2c6bf4eef7"
      },
      "source": [
        "print(\"Average Training Error for FedAvg w/ Adaptive Sampling on SGD = \",average_training_error(w_dyn),\"\\nAverage Testing Error for FedAvg w/ Adaptive Sampling on SGD = \", average_testing_error(w_dyn))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for FedAvg w/ Adaptive Sampling on SGD =  4.96006450863426e-16 \n",
            "Average Testing Error for FedAvg w/ Adaptive Sampling on SGD =  4.5197962733548135e-16\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMjCLbgTHpCQ"
      },
      "source": [
        "## 1.1* Adaptive Sampling with NbA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nas55_b8Hmzz"
      },
      "source": [
        "def device_nbafederated_learning_adap_samp(alp_, w, id, n): #Conducts local training for SGD and outputs weight vector\n",
        "    n_k = no_of_pts(id)\n",
        "    #for i in range(T):\n",
        "      #n_k.append(n_k0)\n",
        "    x_cord, y_cord=fetch_coords(id)\n",
        "    w_ = SGD_(w, n_k, n, x_cord, y_cord, alp_)\n",
        "    #delta=0.01\n",
        "    #eps=2\n",
        "    #C=5.1\n",
        "    #w=np.zeros(len(w_))\n",
        "    #for i in range(len(w)):\n",
        "    #  w[i]=w_[i]*(1/(max([1,w_[i]/C])))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25*delta)*(2*C*max(n_k_dev))/100),len(w))\n",
        "    #w_g=w + np.random.normal(0,2*math.log((1.25/delta)*(C**2))/(eps**2),len(w))\n",
        "    #print(\"w_g = \",w_g)\n",
        "    #s=0.25\n",
        "    #np.random.seed(seed)\n",
        "    #ind=np.random.choice(np.arange(len(w)),size=int((1-s)*len(w)))\n",
        "    #mask = np.zeros(len(w))\n",
        "    #for i in range(len(w)):\n",
        "    #  if i in ind:\n",
        "    #    mask[i]=1\n",
        "    #print(w_g*mask)\n",
        "    return w_,n_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRFvZ9oVHm0E"
      },
      "source": [
        "def SGD_federated_learning_ada_samp(T, K, C, w, n, alp_, beta):\n",
        "    k = np.arange(K)\n",
        "    beta0=beta\n",
        "    error=[]\n",
        "    error_t=0\n",
        "    # Train for T many rounds\n",
        "    for i in range(T):\n",
        "        c=C*(1/math.exp(beta0*i))\n",
        "        w_ = np.zeros((int(c * K), w_n))\n",
        "        n_k = np.zeros(int(c * K))\n",
        "        #seed=np.random.randint(1)\n",
        "        #seeds.append(seed)\n",
        "        training_subset = np.random.randint(0, K, int(c * K))\n",
        "        z=0\n",
        "        #np.random.rand(seed)\n",
        "        for j in training_subset:\n",
        "            w_[z], n_k[z] = device_nbafederated_learning_adap_samp(alp_, w, j, n)\n",
        "            #print(z)\n",
        "            z+=1\n",
        "        w_k = federated_avg(training_subset, w_, n_k)\n",
        "        error.append(average_testing_error(w_k))\n",
        "        #if i>0:\n",
        "        #  if error[i]>error[i-1]:\n",
        "        #    beta0*=(error[i-1]/error[i])*2\n",
        "        #    error_t=error[i-1]\n",
        "        #if beta0!=beta:\n",
        "        #  if error[i]<=error_t:\n",
        "        #    beta0=beta\n",
        "    #w_k = federated_avg(training_subset, w_, n_k)\n",
        "    return w_k"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FCPa2phHm0F",
        "outputId": "b76d8138-3a6f-498a-8475-1862ba70a295"
      },
      "source": [
        "T = 5  # No of federated learning rounds\n",
        "K = 500  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "beta= 0.05\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "w = random.random()\n",
        "b = random.random()\n",
        "n = 100  # number of iteration for local training before pooling\n",
        "alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "n_k = random.randint(10, 100)\n",
        "x_cord1, y_cord1 = get_data(m, n_k)\n",
        "\n",
        "time1 = time.time()\n",
        "w_dyn = SGD_federated_learning_dyn_samp(T, K, C, w, n, alp_, beta)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1,\"\\n w =\",w_dyn)\n",
        "# Device.plot(x_cord, y_cord, w1, b1, n_k)\n",
        "\n",
        "#time1 = time.time()\n",
        "#w2, b2 = Mini_federated_learning(T, K, C, w, b, n, alp_)\n",
        "#time2 = time.time()\n",
        "#print(\"Time taken for Mini-batch SGD federated learning\", time2 - time1)\n",
        "# Device.plot(x_cord, y_cord, w2, b2, n_k)\n",
        "# plt.show()\n",
        "#dat_plot1(x_cord1, y_cord1, w2, b2, n_k, title1=\"NbAFedAvg on SGD\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken for SGD federated learning 333.95433926582336 \n",
            " w = [1.0000001  1.99999997 4.00000007 3.00000008 4.99999994 5.99999987\n",
            " 1.19999998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVIdtEcGHm0G",
        "outputId": "1bed3bcc-2ad8-41d8-9ecb-caef9f6b6646"
      },
      "source": [
        "print(\"Average Training Error for FedAvg w/ Dyn Sampling on SGD = \",average_training_error(w_dyn),\"\\nAverage Testing Error for FedAvg w/ Dyn Sampling on SGD = \", average_testing_error(w_dyn))\n",
        "print(\" Actual weights, m = \",m)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Error for FedAvg w/ Dyn Sampling on SGD =  3.7190119635908776e-15 \n",
            "Average Testing Error for FedAvg w/ Dyn Sampling on SGD =  3.060815956838882e-15\n",
            " Actual weights, m =  [1, 2, 4, 3, 5, 6, 1.2]\n"
          ]
        }
      ]
    }
  ]
}