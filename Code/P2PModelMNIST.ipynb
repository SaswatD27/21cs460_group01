{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P2PModelMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaswatD27/21cs460_group01/blob/main/Code/P2PModelMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_cGo_SSDYEJ"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "#from tensorflow_federated import federated_mean\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "from copy import deepcopy\n",
        "from statistics import mean\n",
        "\n",
        "\n",
        "#print(x_cord, y_cord)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFpbNcCx9bSU"
      },
      "source": [
        "#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "#emnist_train, emnist_test = datasets.emnist.load_data()\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObPH7KU8AFSg"
      },
      "source": [
        "K=100\n",
        "n_k_dev= np.random.randint(100,600,K)\n",
        "#n_k=[600 for i in range(K)]\n",
        "n_tot=sum(n_k_dev)\n",
        "client_images=deepcopy(list(range(len(train_images))))\n",
        "random.shuffle(client_images)\n",
        "#print(lenMNIST)\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "'''\n",
        "for i in range(K):\n",
        "  x_train.append([])\n",
        "  y_train.append([])\n",
        "  for j in range(n_k[i]):\n",
        "    k=client_images.pop()\n",
        "    x_train[i].append(train_images[k])\n",
        "    y_train[i].append(train_labels[k])\n",
        "'''\n",
        "indices_dev=[]\n",
        "for i in range(K):\n",
        "  indices_dev.append([])\n",
        "  for j in range(n_k_dev[i]):\n",
        "    k=client_images.pop()\n",
        "    indices_dev[i].append(k)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqqVJDfx08Qk"
      },
      "source": [
        "'''\n",
        "def SGD_(m, n, iteration, x_cord, y_cord, alpha):  # Performs client side SGD\n",
        "    for p in range(iteration):\n",
        "        for i in range(n):\n",
        "            j = random.randint(0, n - 1)\n",
        "            x_i = x_cord[j]\n",
        "            y_a = y_cord[j]\n",
        "            y_p = np.dot(m, x_i)\n",
        "            dm = 2 * x_i * (y_p - y_a)\n",
        "            m = m - alpha * dm\n",
        "    return m\n",
        "'''\n",
        "\n",
        "def no_of_pts(id):\n",
        "    return n_k_dev[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnfYdOaF9nWE"
      },
      "source": [
        "#works!\n",
        "def create_DNN():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  #model.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax')) \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrFYp4wmlKAC"
      },
      "source": [
        "server_model=create_DNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwjNE0-DeSl"
      },
      "source": [
        "def device_local_learning(ini_model,id): #Conducts local training for SGD and outputs weight vector\n",
        "    model=ini_model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    history = model.fit(train_images[indices_dev[id]],train_labels[indices_dev[id]], epochs=20, validation_data=(test_images, test_labels), verbose=0)\n",
        "    #print(id,\" done.\")\n",
        "    save_weight(model, n_k_dev[id], id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UymAkdYQxG-r"
      },
      "source": [
        "def save_weight(w,n_k,id):\n",
        "    n_k_devices[id]=n_k\n",
        "    fl = str(id)\n",
        "    #file = open(fl + \"_wn.dat\", \"w\")\n",
        "    w.save_weights(fl + \"_wn\")\n",
        "    #file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-G62xM9M-W"
      },
      "source": [
        "def avg_weights(client_frac,client_models,n_clients_round):\n",
        "  client_models=np.array(client_models)\n",
        "  res=client_frac[0]*np.array(client_models[0].get_weights())\n",
        "  #print(res)\n",
        "  for i in range(1,n_clients_round):\n",
        "    res+=client_frac[i]*np.array(client_models[i].get_weights())\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmnaW0m2m7N9"
      },
      "source": [
        "#FED_AVG_DNN : WORKS NOW\n",
        "def fed_avg_DNN(client_models, client_n):\n",
        "  fin_model=create_DNN()\n",
        "  fin_model.set_weights(0*np.array(fin_model.get_weights()))\n",
        "  client_frac=np.zeros(len(client_n))\n",
        "  for i in range(len(client_n)):\n",
        "    client_frac[i]=(client_n[i])*(1/np.sum(client_n))\n",
        "  #print(\"Sum of client_frac = \",np.sum(client_frac),\" client_frac = \",client_frac)\n",
        "  #client_weights_sum=np.sum(client_models)\n",
        "  #for layer in server_model.layers:\n",
        "  #  layer.set_weights([np.dot(client_frac,client_model.get_weights()[0]),np.dot(client_frac,client_model.get_weights()[1])])\n",
        "  #server_model.set_weights([np.dot(client_frac,[m.get_weights()[0] for m in client_models]),np.dot(client_frac,[m.get_weights()[1] for m in client_models])])\n",
        "  fin_model.set_weights(avg_weights(client_frac,client_models,len(client_frac)))\n",
        "  return fin_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALNhJSfY06pV"
      },
      "source": [
        "def request_dat(initiate):\n",
        "    w_n=create_DNN()\n",
        "    fl = str(initiate)\n",
        "    w_n.load_weights(fl + \"_wn\").expect_partial()\n",
        "    n_k_new= n_k_devices[initiate]\n",
        "    return w_n,n_k_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuAdo1rR3wye"
      },
      "source": [
        "def communicate(w_o, training_subset,n_k):\n",
        "    comm_len= np.random.randint(1,max(len(training_subset),2))\n",
        "    call_to = np.random.choice(training_subset,comm_len)\n",
        "    print(call_to, \"---\", w_o)\n",
        "    w_=[]\n",
        "    n_=[]\n",
        "    w_.append(w_o)\n",
        "    n_.append(n_k)\n",
        "    for i in call_to:\n",
        "        w_w,n_w=request_dat(i)\n",
        "        w_.append(w_w)\n",
        "        n_.append(n_w)\n",
        "    w_new=fed_avg_DNN(w_,n_)\n",
        "    w_o.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "    w_new.compile(optimizer='adam',loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "    w_new.save_weights(\"w_new\")\n",
        "    err_o=1-w_o.evaluate(test_images,  test_labels, verbose=2)[1]\n",
        "    err_1=1-w_new.evaluate(test_images,  test_labels, verbose=2)[1]\n",
        "    if err_1<err_o:\n",
        "        return w_new\n",
        "    else:\n",
        "        return w_o"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55YxFl-Q3lPB"
      },
      "source": [
        "def p2p_learn(initiate,training_subset):\n",
        "    w_n,n_k_new=request_dat(initiate)\n",
        "    training_subset_c=training_subset.copy()\n",
        "    training_subset_c=training_subset_c.tolist()\n",
        "    training_subset_c.remove(initiate)\n",
        "    w_new=communicate(w_n,training_subset_c,n_k_new)\n",
        "    return w_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQoYjuuuUKlN"
      },
      "source": [
        "def P2P_new_fed1(K, C, server_model, n):\n",
        "    training_subset = np.random.choice(all_device, int(C * K), replace=False)\n",
        "    print(training_subset)\n",
        "    ini_model=create_DNN()\n",
        "    try:\n",
        "        ini_model.load_weights(\"w_new\")\n",
        "    except:\n",
        "        ini_model=server_model\n",
        "    for j in training_subset:\n",
        "        device_local_learning(ini_model,j)\n",
        "    print(\"Initial Model sent.\")\n",
        "    w_new=[]\n",
        "    acc=[]\n",
        "    for i in training_subset:\n",
        "        w_new.append(p2p_learn(i,training_subset))\n",
        "        '''\n",
        "        for i in training_subset:\n",
        "            i = str(i)\n",
        "            os.remove(i + \"_wn\")\n",
        "        '''\n",
        "    for w in w_new:\n",
        "      acc.append(w.evaluate(test_images,  test_labels, verbose=0)[1])\n",
        "    print(\"Accuracies for new models via P2P are\",acc,\"\\n Max Accuracy = \",max(acc),\"\\n Min Accuracy = \",min(acc),\"\\n Mean Accuracy = \",np.mean(acc))\n",
        "    ind_acc=[i for i in range(len(acc))]\n",
        "    plt.scatter(ind_acc,acc)\n",
        "    plt.xlabel('Clients in Training Sample')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('P2P Model : Accuracy of Individual Clients')\n",
        "    plt.show()\n",
        "    ini_model.load_weights(\"w_new\")\n",
        "    print(ini_model.evaluate(test_images,  test_labels, verbose=0)[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3-mPl721Hi5"
      },
      "source": [
        "#To run another subsequent round, simply hit run again; prior weights, if any, are saved.\n",
        "K = 100\n",
        "C = 0.25\n",
        "B= int(K * C)\n",
        "#error_ = 10 ** (-4)\n",
        "#w_i = np.random.rand(len(m))\n",
        "n = 20\n",
        "#alph_ = 0.01  # local learning rate\n",
        "\n",
        "'''\n",
        "device_list = []\n",
        "for q in range(B):\n",
        "    device_list.append('device_%i' % (q + 1))\n",
        "'''\n",
        "n_k_devices=np.zeros(K)\n",
        "all_device=np.arange(K)\n",
        "\n",
        "\n",
        "time1 = time.time()\n",
        "P2P_new_fed1(K, C, server_model, n)\n",
        "time2 = time.time()\n",
        "print(\"Time taken for P2P federated learning\", time2 - time1)\n",
        "print(n_k_devices)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaSa-IfM32kb"
      },
      "source": [
        "#Plot\n",
        "max_acc=[93.83999705314636,94.30999755859375,94.8199987411499,94.9999988079071,94.98000144958496,95.09000182151794,95.13999819755554]\n",
        "min_acc=[92.66999959945679,92.76999831199646,93.97000074386597,93.80000233650208,94.37999725341797,94.24999952316284,93.80000233650208]\n",
        "mean_acc=[93.49119901657105,94.02160000801086,94.4760000705719,94.62239980697632,94.7564001083374,94.24999952316284,94.90360021591187]\n",
        "global_acc=[93.79000067710876,94.24999952316284,94.74999904632568,94.70999836921692,94.87000107765198,94.85240006446838,94.91999745368958]\n",
        "x_cords_plt=range(1,8)\n",
        "plt.plot(x_cords_plt,max_acc, label='Max Cluster Acc')\n",
        "plt.plot(x_cords_plt,global_acc, label='Shared Global Model Acc')\n",
        "plt.plot(x_cords_plt,mean_acc, label='Mean Cluster Acc')\n",
        "plt.plot(x_cords_plt,min_acc, label='Min Cluster Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}