{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS460_FL_1_02_Functional.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaswatD27/21cs460_group01/blob/main/Code/CS460_FL_1_02_Functional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0HdWCBSThU5"
      },
      "source": [
        "## Notes\n",
        "* Current client side implementation just helps create initial model; no server2client communication yet, no preexisting initial model. Is this necessary? Don't think so, not for now.\n",
        "* Will Noising before Aggregation FL work? Let us see. Perhaps the exponential mechanism will be better. (Implemented, works, hmm... what's the error margin now?)\n",
        "* Need to add error/loss function graph\n",
        "* Need to decouple n_k from training functions to apply some algorithms and make it more natural - Update: Done\n",
        "* IMPORTANT:  Need testing set (might not but still, for propriety; client-side) - Update: Done\n",
        "* Gaussian noise addition (Client side) works but might be identifying, implement mixes/LDP/random subsampling of returned weights?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E58-dIg2yGo"
      },
      "source": [
        "## Bootstrapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_cGo_SSDYEJ"
      },
      "source": [
        "import random\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow import keras\n",
        "from copy import deepcopy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCne8LZN-SHN"
      },
      "source": [
        "## Loading MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFpbNcCx9bSU"
      },
      "source": [
        "#(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "#emnist_train, emnist_test = datasets.emnist.load_data()\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "img_rows, img_cols = 28, 28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMiecRFDCCp2"
      },
      "source": [
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsxhFnPcUJR8"
      },
      "source": [
        "### Partitioning MNIST (indices) for clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObPH7KU8AFSg"
      },
      "source": [
        "K=100\n",
        "n_k= np.random.randint(100,600,K)\n",
        "n_tot=sum(n_k)\n",
        "client_images=deepcopy(list(range(len(train_images))))\n",
        "random.shuffle(client_images)\n",
        "x_train=[]\n",
        "y_train=[]\n",
        "'''\n",
        "for i in range(K):\n",
        "  x_train.append([])\n",
        "  y_train.append([])\n",
        "  for j in range(n_k[i]):\n",
        "    k=client_images.pop()\n",
        "    x_train[i].append(train_images[k])\n",
        "    y_train[i].append(train_labels[k])\n",
        "'''\n",
        "indices_dev=[]\n",
        "for i in range(K):\n",
        "  indices_dev.append([])\n",
        "  for j in range(n_k[i]):\n",
        "    k=client_images.pop()\n",
        "    indices_dev[i].append(k)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CuoBt2F_DP"
      },
      "source": [
        "print(type(np.array(x_train,dtype=object)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLD3KMkohh1"
      },
      "source": [
        "print(n_tot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlsKhZJ1CHhn"
      },
      "source": [
        "## Defining DNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnfYdOaF9nWE"
      },
      "source": [
        "#Creating DNN using tensorflow\n",
        "def create_DNN():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(units=32, activation='relu')) \n",
        "  #model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "  #model.add(tf.keras.layers.Dense(units=512))\n",
        "  model.add(tf.keras.layers.BatchNormalization())\n",
        "  model.add(tf.keras.layers.Dense(units=10, activation='softmax')) \n",
        "  #model.add(tf.keras.layers.BatchNormalization())\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Dm14F8r-UUc"
      },
      "source": [
        "##0. Centralised Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Tk3Eq29roM"
      },
      "source": [
        "model=create_DNN()\n",
        "model.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(np.array(model.get_weights()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKPB9KSl9zNI"
      },
      "source": [
        "#Training Model\n",
        "#history = model.fit(train_images[indices_dev[0]], train_labels[indices_dev[0]], epochs=25, validation_data=(test_images, test_labels))\n",
        "history = model.fit(train_images, train_labels, epochs=50, validation_data=(test_images, test_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ97-6sK99ki"
      },
      "source": [
        "#Plotting Accuracy Graph\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huHcwYNK-BSo"
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kU7ncCI3P9yI"
      },
      "source": [
        "print((model.get_weights()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ2emIGuGSqk"
      },
      "source": [
        "## Client Side Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwjNE0-DeSl"
      },
      "source": [
        "#Conducts local training and outputs weight vector\n",
        "def device_local_learning(server_model,id): \n",
        "    model=server_model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    #Training the model using own data\n",
        "    history = model.fit(train_images[indices_dev[id]],train_labels[indices_dev[id]], epochs=20, validation_data=(test_images, test_labels), verbose=0)\n",
        "    \n",
        "    return model, n_k[id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2Wxa0OlT0b8"
      },
      "source": [
        "## Server Side\n",
        "### 1. FedAvg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrFYp4wmlKAC"
      },
      "source": [
        "#Server making intial model\n",
        "server_model=create_DNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj-G62xM9M-W"
      },
      "source": [
        "#Averages weights as part of FedAveraging\n",
        "def avg_weights(client_frac,client_models,n_clients_round):\n",
        "  client_models=np.array(client_models)\n",
        "  res=client_frac[0]*np.array(client_models[0].get_weights())\n",
        "  #print(res)\n",
        "  for i in range(1,n_clients_round):\n",
        "    res+=client_frac[i]*np.array(client_models[i].get_weights())\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmnaW0m2m7N9"
      },
      "source": [
        "#Federated Averaging: Tensorflow/Keras Sequential compatible\n",
        "def fed_avg_DNN(server_model, client_models, client_n):\n",
        "  client_frac=np.zeros(len(client_n))\n",
        "  for i in range(len(client_n)):\n",
        "    client_frac[i]=(client_n[i])*(1/np.sum(client_n))\n",
        "  server_model.set_weights(avg_weights(client_frac,client_models,len(client_frac)))\n",
        "  return server_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOaWfVvYkbrM"
      },
      "source": [
        "#Conducts the entire process of FL with vanilla FedAveraging\n",
        "def fed_learning(T, K, C, server_model):\n",
        "  client_models=[]\n",
        "  client_n=[]\n",
        "  test_err=[]\n",
        "  z=0\n",
        "  for i in range(T):\n",
        "    training_subset = np.random.randint(0, K, int(C * K))\n",
        "    #z=0\n",
        "    for j in training_subset:\n",
        "      w,n_c=device_local_learning(server_model,j)\n",
        "      client_models.append(w)\n",
        "      client_n.append(n_c)\n",
        "      z+=1\n",
        "  \n",
        "    model_fin = fed_avg_DNN(server_model, client_models[:z], client_n[:z])#\n",
        "    model_fin.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    test_err.append(model_fin.evaluate(test_images,  test_labels, verbose=0))\n",
        "    print(i,\" done.\",\"\\n size =\",len(client_models),\" Accuracy : \",test_err[-1][1])\n",
        "    \n",
        "  return model_fin, test_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UBFg7nx22rf"
      },
      "source": [
        "#Defining Parameters and Running the abovementioned functions\n",
        "T = 20  # No of federated learning rounds\n",
        "K = 100  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "# B = #Local batch size used at each learning iteration\n",
        "# random Model\n",
        "#w = np.random.rand(7)\n",
        "#n = 100  # number of iteration for local training before pooling\n",
        "#alp_ = 0.01  # local learning rate\n",
        "#m = 5\n",
        "\n",
        "time1 = time.time()\n",
        "model_fin, test_err = fed_learning(T, K, C, server_model) #test_err = list of (loss, test error) tuples\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1)#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLQ3bw8qEnG2"
      },
      "source": [
        "#OPTIONAL: Very verbose, lots of numbers\n",
        "print(model_fin.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuurQ41wHlfJ"
      },
      "source": [
        "#Not essential to run\n",
        "model_fin.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoDw7G2EHQHS"
      },
      "source": [
        "test_loss, test_acc = model_fin.evaluate(test_images,  test_labels, verbose=2)\n",
        "model_fin.evaluate(train_images, train_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCANh6c9Ls85"
      },
      "source": [
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1qruiHKUaJW"
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRg3Rhs-V5Nq"
      },
      "source": [
        "# MUST RUN FOR CREATING PLOT\n",
        "test_err_acc = [a[1] for a in test_err]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FVwQI3QUFba"
      },
      "source": [
        "#Creates Error Plot\n",
        "number=np.arange(1,len(test_err_acc)+1)\n",
        "plt.plot(number, test_err_acc, color='Blue')\n",
        "plt.xlabel('No. of Communication Rounds')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('DNN on MNIST : Accuracy w.r.t No. of Communication Rounds')\n",
        "#plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch7tzCn3JMZH"
      },
      "source": [
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trbrkRj2GkW_"
      },
      "source": [
        "## 1. Dynamic Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeuEiRCLG4q7"
      },
      "source": [
        "#Conducts FL with dynamic sampling\n",
        "server_model_dyn=server_model\n",
        "def fed_learning_dyn_samp(T, K, C, server_model, beta):\n",
        "  client_models=[]\n",
        "  client_n=[]\n",
        "  test_err=[]\n",
        "  z=0\n",
        "  for i in range(T):\n",
        "    c=C*(1/math.exp(beta*i)) #Sampling Rate Downscaled\n",
        "    training_subset = np.random.randint(0, K, max(1,int(c * K)))\n",
        "    #z=0\n",
        "    for j in training_subset:\n",
        "      w,n_c=device_local_learning(server_model,j)\n",
        "      client_models.append(w)\n",
        "      client_n.append(n_c)\n",
        "      #print(z)\n",
        "      z+=1\n",
        "    #for i in range(len(client_models)):\n",
        "    #  test_loss,test_acc=client_models[i].evaluate(test_images,  test_labels, verbose=2)\n",
        "    #  print(test_acc)\n",
        "    model_fin = fed_avg_DNN(server_model, client_models[:z], client_n[:z])#\n",
        "    model_fin.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    test_err.append(model_fin.evaluate(test_images,  test_labels, verbose=0))\n",
        "    print(i,\" done.\",\"\\n size =\",len(client_models),\" Accuracy : \",test_err[-1][1])\n",
        "    #for i in range(len(client_models)):\n",
        "    #  print(\"\\n Client - \", i, \" sends \\n\",client_models[i].get_weights())\n",
        "  return model_fin, test_err"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-QhkC09HNJe"
      },
      "source": [
        "#Runs the dynamic sampling model\n",
        "T = 20  # No of federated learning rounds\n",
        "K = 100  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25\n",
        "beta = 0.05\n",
        "\n",
        "time1 = time.time()\n",
        "model_fin, test_err = fed_learning_dyn_samp(T, K, C, server_model_dyn, beta) #test_err = list of (loss, test error) tuples\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1)#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS7SK7W0wksd"
      },
      "source": [
        "print(model_fin.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v_fvV5_wksl"
      },
      "source": [
        "test_loss, test_acc = model_fin.evaluate(test_images,  test_labels, verbose=2)\n",
        "model_fin.evaluate(train_images, train_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j55BS_zRwksl"
      },
      "source": [
        "print(test_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Crrukiwksm"
      },
      "source": [
        "#MUST RUN TO GET PLOT\n",
        "test_err_acc = [a[1] for a in test_err]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Inodqijvwksm"
      },
      "source": [
        "#Code to Plot, run this\n",
        "number=np.arange(1,len(test_err_acc)+1)\n",
        "plt.plot(number, test_err_acc, color='Blue')\n",
        "plt.xlabel('No. of Communication Rounds')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('DNN on MNIST : Accuracy w.r.t No. of Communication Rounds')\n",
        "#plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdn6Q8ulGgEB"
      },
      "source": [
        "## 1*. Adaptive Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwGKeb5_D96K"
      },
      "source": [
        "#Creates initial server model for the very first run (after start of runtime)\n",
        "server_model=create_DNN()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2KT9uSbh_er"
      },
      "source": [
        "#Runs the adaptive sampling protocol\n",
        "def fed_learning_adap_samp(T, K, C, server_model, beta, gamma):\n",
        "  client_models=[]\n",
        "  client_n=[]\n",
        "  test_acc=[]\n",
        "  error=[]\n",
        "  z=0\n",
        "  i0=0\n",
        "  error_t=0\n",
        "  beta0=beta\n",
        "  for i in range(T):\n",
        "    c=C*(1/math.exp(beta0*i0)) #Decay of sampling rate\n",
        "    training_subset = np.random.randint(0, K, max(1,int(c * K)))\n",
        "    #z=0\n",
        "    for j in training_subset:\n",
        "      w,n_c=device_local_learning(server_model,j)\n",
        "      client_models.append(w)\n",
        "      client_n.append(n_c)\n",
        "      #print(z)\n",
        "      z+=1\n",
        "    \n",
        "    model_fin = fed_avg_DNN(server_model, client_models[:z], client_n[:z])#\n",
        "    model_fin.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])\n",
        "    test_acc.append(model_fin.evaluate(test_images,  test_labels, verbose=0))\n",
        "    error.append((1-test_acc[-1][1]))\n",
        "    '''\n",
        "    if i>0:\n",
        "      if error[i]>error[i-1]:\n",
        "        mult=((error[i-1]/error[i])**2)*(1/gamma)#*(i/i+1))\n",
        "        print(\"Multiplier = \",mult)\n",
        "        beta0*=mult\n",
        "        print(\"New Decay Constant = \",beta0)\n",
        "        if error_t==0:\n",
        "          error_t=error[i-1]\n",
        "        else:\n",
        "          i0=i+1\n",
        "          if error[i]<=error_t:\n",
        "            beta0=beta\n",
        "            error_t=0\n",
        "            print(\"Beta = \",beta,\" restored!\")\n",
        "    else:\n",
        "      i0=1\n",
        "    print(i+1,\" done. Error = \", err_r)\n",
        "    '''\n",
        "    if i>0:\n",
        "      if test_acc[i][1]<test_acc[i-1][1]: #Error increase detection\n",
        "        multiplier=((1-test_acc[i-1][1])/(1-test_acc[i][1])) #If yes, then penalise w.r.t. the currently observed and prev round's error \n",
        "        beta0*=multiplier*gamma #Penalisation of decay coefficient\n",
        "        if error_t==0:\n",
        "          error_t=error[i-1] #Record error threshold to reattain if error threshold does not exist\n",
        "        print(\" Multiplier  = \", multiplier,\"\\n New Decay Constant = \",beta0)\n",
        "      else:\n",
        "        i0=i+1 #All good, can increase counter in sampling rate decay formula\n",
        "        if error[i]<=error_t: #If error level falls below the threshold, restore the decay coeff!\n",
        "          beta0=beta\n",
        "          error_t=0\n",
        "          print(\"Beta = \",beta,\" restored!\")\n",
        "    else:\n",
        "      i0=1\n",
        "    #for i in range(len(client_models)):\n",
        "    #  print(\"\\n Client - \", i, \" sends \\n\",client_models[i].get_weights())\n",
        "    print(i,\" done.\",\"\\n size =\",len(client_models),\" Accuracy : \",test_acc[-1][1],\" Decay Coefficient : \",beta0)\n",
        "  return model_fin, test_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5-4KqWuiDCn"
      },
      "source": [
        "#Runs the adaptive sampling model\n",
        "T = 20  # No of federated learning rounds\n",
        "K = 100  # Total no of nodes\n",
        "#C = 0.7  # fraction of nodes used at each iteration\n",
        "C=0.25 #initial sampling rate\n",
        "beta = 0.05\n",
        "gamma = 1\n",
        "\n",
        "time1 = time.time()\n",
        "model_fin_adap, test_err_adap = fed_learning_adap_samp(T, K, C, server_model, beta, gamma) #test_err = list of (loss, test error) tuples\n",
        "time2 = time.time()\n",
        "print(\"Time taken for SGD federated learning\", time2 - time1)#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK_1l9qoryJP"
      },
      "source": [
        "#Optional: Very verbose\n",
        "print(model_fin_adap.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DKTnuGMryJV"
      },
      "source": [
        "#Not necessary to run, works just fine (probably redundant code)\n",
        "model_fin_adap.compile(optimizer='adam',\n",
        "                  loss=\"sparse_categorical_crossentropy\",\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46rigJCgryJV"
      },
      "source": [
        "test_loss, test_acc = model_fin_adap.evaluate(test_images,  test_labels, verbose=2)\n",
        "model_fin_adap.evaluate(train_images, train_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrAc9e9IryJW"
      },
      "source": [
        "print(test_err_adap)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqAdlEPtr90Y"
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U4qF0ktr90Y"
      },
      "source": [
        "#MUST RUN TO GET PLOT\n",
        "test_err_acc = [a[1] for a in test_err_adap]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJnE_-Jvr90Y"
      },
      "source": [
        "#Run to get error plot\n",
        "number=np.arange(1,len(test_err_acc)+1)\n",
        "plt.plot(number, test_err_acc, color='Blue')\n",
        "plt.xlabel('No. of Communication Rounds')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('DNN on MNIST with Adaptive Sampling : Accuracy w.r.t No. of Communication Rounds')\n",
        "#plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}